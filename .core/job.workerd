#!/usr/bin/perl
BEGIN
{
	$TOM::engine='job';
	if ($ARGV[0] eq "debug"){$main::debug=1;shift @ARGV;}
		$main::debug=1 if $ENV{'CYCLONE3DEBUG'};
	if (!$ENV{'CYCLONE3PATH'})
	{
		$ENV{'CYCLONE3PATH'}="/www/TOM" if -d "/www/TOM"; # obsolete
		$ENV{'CYCLONE3PATH'}="/Cyclone3" if -d "/Cyclone3";
		$ENV{'CYCLONE3PATH'}="/srv/Cyclone3" if -d "/srv/Cyclone3";
	}
	require $ENV{'CYCLONE3PATH'}."/.core/.libs/TOM.pm";
	$TOM::engine.='.workerd';
	$0.=".workerd";
	$TOM::DEBUG_log_file=90;
#	setpriority $$,$$,19;
}

use open ':utf8', ':std';
use if $] < 5.018, 'encoding','utf8';
use utf8; # encode = fromutf8, decode=toutf8
use strict; # scrict code
use vars qw//;
our $sig_term=1;

our $argv=join " ",@ARGV;
our %arg;
foreach my $key(@ARGV)
{
	$key=~s/^\-\-// && do
	{
		my @ref=split('=',$key,2);
		$ref[1]=1 unless exists $ref[1];
		$main::arg{$ref[0]}=$ref[1];
		next;
	};
	$key=~s/^\-// && do
	{
		foreach (split('',$key)){$main::arg{$_}++;}
	};
}


######################################################################################
######################################################################################

$main::request_code=Utils::vars::genhash(8);
my $t0=track TOM::Debug('TOM::Engine::job');
require TOM::Engine::job;
TOM::Database::connect::multi('main','sys')
	|| die "Error during connection request to database server\n";
$t0->close();

use Encode qw(decode encode);
use JSON;
use Data::Dumper;
use Ext::Redis::_init;
use LWP::UserAgent;
use AnyEvent;
use Coro;
use AnyEvent::ForkManager;
use Proc::ProcessTable;
#use Sys::Info;
use Sys::Statistics::Linux;
use Sys::Statistics::Linux::SysInfo;
use Sys::Statistics::Linux::LoadAVG;
use Sys::Statistics::Linux::MemStats;
#use Sys::CpuLoad;
#use Sys::Info::Constants qw( :device_cpu );

# main loop AnyEvent
my $main_loop = AnyEvent->condvar;

# connect RabbitMQ
our $service=Ext::RabbitMQ::service();
our $do=new class_do;

# test API
my $ua = LWP::UserAgent->new;
my $uri='http://'.$Ext::RabbitMQ::user.':'.$Ext::RabbitMQ::pass.'@'.$Ext::RabbitMQ::host.':15672/api';
my $response = $ua->get($uri.'/queues');
if (!$response->is_success)
{
	die "can't connect to RabbitMQ API (".$response->status_line.")";
}

my $sysinfo  = Sys::Statistics::Linux::SysInfo->new;
my $sysstat = $sysinfo->get;

my $meminfo = Sys::Statistics::Linux::MemStats->new;
my $memstat = $meminfo->get;

my $loadinfo = Sys::Statistics::Linux::LoadAVG->new;
my $loadstat = $loadinfo->get;

$main::arg{'mode'}||='master';
main::_log_stdout("running in mode '".$main::arg{'mode'}."' on host with ".$sysstat->{'tcpucount'}." CPU cores PID $$",3,"job.workerd");# if $ENV{'WORKERS'};
our $MAX_LOAD=int($sysstat->{'tcpucount'} * 2);
main::_log_stdout("max allowed load $MAX_LOAD",3,"job.workerd");# if $ENV{'WORKERS'};

main::_log_stdout("declaring default job exchange, queue, binding",3,"job.workerd");

# cyclone3.job
$service->_channel->declare_exchange(
	'exchange' => encode('UTF-8', 'cyclone3.job'),
	'type' => encode('UTF-8', 'direct'),
	'durable' => 1);
	# cyclone3.job: job -> cyclone3.job
	$service->_channel->declare_queue( # global job queue
		'exchange' => encode('UTF-8', 'cyclone3.job'),
		'queue' => encode('UTF-8', 'cyclone3.job._global'),
		'durable' => 1);
	$service->_channel->bind_queue(
		'exchange' => encode('UTF-8', 'cyclone3.job'),
		'routing_key' => encode('UTF-8', 'job'),
		'queue' => encode('UTF-8', 'cyclone3.job._global')
	);

# notify channel to generate triggers
$service->_channel->declare_exchange(
	'exchange' => encode('UTF-8', 'cyclone3.notify'),
	'type' => encode('UTF-8', 'direct'),
	'durable' => 1);

our $notify_channel=$Ext::RabbitMQ::service->open_channel();
	$notify_channel->declare_queue(
		'exchange' => encode('UTF-8', 'cyclone3.notify'),
		'queue' => encode('UTF-8', 'cyclone3.notify'),
		'durable' => 1
	);
	$notify_channel->bind_queue(
		'exchange' => encode('UTF-8', 'cyclone3.notify'),
		'routing_key' => encode('UTF-8', 'notify'),
		'queue' => encode('UTF-8', 'cyclone3.notify')
	);

	
our %domain_info;
our %domain_worker;
our %config_file;
check_processes();
check_domains();

sub get_workers
{
	use Proc::ProcessTable;
	my $t = new Proc::ProcessTable;
	return (scalar (grep {$_->{'cmndline'}=~/^c3\-job\.worker/;} @{$t->table}))-1;
}

our $WORKERS = get_workers();
my $MAX_WORKERS = $TOM::job_host_max_processes || ($sysstat->{'tcpucount'} * 4) +1;
$ENV{'WORKERS'}=1 unless exists $ENV{'WORKERS'}; # spawning workers?
$ENV{'AUTORESTART'}=1 unless exists $ENV{'AUTORESTART'}; # spawning workers?
$TOM::job_domain_max_workers||=16; # max X workers parallel on same domain
$TOM::job_worker_start_delay||=1; # start next worker after delay
$TOM::job_domain_worker_start_delay||=5; # start next worker after delay on same domain

our $usable_memory = (
	($memstat->{'memfree'} - ($memstat->{'memtotal'} * 0.01)) # reserve 1%
	+ ($memstat->{'cached'} - ($memstat->{'memtotal'} * 0.01)) # +1% filesystem cache reserve
);
main::_log_stdout("max $MAX_WORKERS workers (allowed to fork?=$ENV{'WORKERS'}), max load is allowed $MAX_LOAD, usable free memory ".(int(($usable_memory/1024/1024)*100)/100)."GB for ".int($usable_memory/200000)." workers",3,"job.workerd");

#exit if $main::arg{'mode'} eq "slave";

main::_log_stdout("main loop timer starting",3,"job.workerd") if $ENV{'WORKERS'};
my $w=AnyEvent->timer(after => 1, interval => 5, cb => sub {
	$main::request_code=Utils::vars::genhash(8);
#	main::_log_stdout("controlling job queue pool");
	local $main::_canexit;
	
	$WORKERS = get_workers();
	
	main::_log("active workers \@$TOM::hostname ".$WORKERS."/".$MAX_WORKERS,3,"job.workerd");
	
	$loadstat = $loadinfo->get;
	my $load=$loadstat->{'avg_5'};#(Sys::CpuLoad::load())[1];
	if ($load >= $MAX_LOAD && $WORKERS > 1)
	{
		main::_log("high load ($load) \@$TOM::hostname, skip spawning",3,"job.workerd");
		return undef;
	}
	
	my $memstat = $meminfo->get;
	$usable_memory = (
		($memstat->{'memfree'} - ($memstat->{'memtotal'} * 0.05)) # reserve 5%
		+ ($memstat->{'cached'} - ($memstat->{'memtotal'} * 0.05)) # +5% filesystem cache reserver
	);
	if ($usable_memory < 200000 && $WORKERS > 1)
	{
		main::_log("usable memory too low (".($usable_memory)."kb) \@$TOM::hostname, skip spawning",3,"job.workerd");
		return undef;
	}
	
	my $response = $ua->get($uri.'/queues');
	if (!$response->is_success)
	{
		die "can't connect to RabbitMQ API (".$response->status_line.")";
	}
	
	my $content=$response->decoded_content;
	
	my $data=from_json($content);
	
#	print Dumper($data);
=head1
	{
		'messages_ready' => 0,
		'messages_ready_details' => {
			'rate' => '0'
		},
		'status' => 'running',
		'node' => 'rabbit@app-01',
		'vhost' => '/',
		'policy' => '',
		'messages_unacknowledged_details' => {
			'rate' => '0'
		},
		'idle_since' => '2014-03-28 16:02:56',
		'messages' => 0,
		'durable' => bless( do{\(my $o = 0)}, 'JSON::XS::Boolean' ),
		'messages_unacknowledged' => 0,
		'name' => '[app-01:23433] exclusive callback',
		'owner_pid_details' => {
			'peer_port' => 42863,
			'name' => '127.0.0.1:42863 -> 127.0.0.1:5672',
			'peer_host' => '127.0.0.1'
		},
		'auto_delete' => $VAR1->[0]{'durable'},
		'messages_details' => {
			'rate' => '0'
		},
		'memory' => 6600,
		'consumers' => 0,
		'arguments' => {},
		'backing_queue_status' => {
			'len' => 0,
			'next_seq_id' => 0,
			'ram_ack_count' => 0,
			'avg_egress_rate' => '0',
			'q2' => 0,
			'avg_ingress_rate' => '0',
			'q3' => 0,
			'pending_acks' => 0,
			'avg_ack_ingress_rate' => '0',
			'avg_ack_egress_rate' => '0',
			'q4' => 0,
			'q1' => 0,
			'delta' => [
				'delta',
				'undefined',
				0,
				'undefined'
			],
			'target_ram_count' => 'infinity',
			'persistent_count' => 0,
			'ram_msg_count' => 0
		},
		'exclusive_consumer_tag' => ''
	},
=cut
	
	my $started;
	foreach my $queue (sort {($b->{'messages_ready'}/($b->{'consumers'}+1)) <=> ($a->{'messages_ready'}/($a->{'consumers'}+1))} grep {$_->{'name'}=~/^cyclone3\.job\./} @{$data})
	{
		my $domain=$queue->{'name'};
			$domain=~s|^cyclone3\.job\.||;
		
		my $class;
			$class=$2 if $domain=~s|^(.*)(::.*?)$|$1|;
		my $class_=$class;
			$class=~s|^::||;
		
		if ($main::arg{'class'})
		{
			next unless $class eq $main::arg{'class'};
		}
		
		if ($domain=~/^db:(.*?)$/)
		{
			undef $domain;
			my $db_name=$1;
			if ($db_name eq "TOM")
			{
				$domain = "_global";
			}
			else
			{
#			main::_log_stdout("queue '$queue->{'name'}' db='$db_name' jobs=".$queue->{'messages_ready'}." rate=".$queue->{'messages_ready_details'}->{'rate'}." workers=".$queue->{'consumers'});
				foreach (sort {length($a) <=> length($b) || $a cmp $b} keys %domain_info)
				{
					if ($domain_info{$_}->{'db_name'} eq $db_name)
					{
						$domain=$_;
						last;
					}
				}
			}
			next unless $domain;
		}
		
		# set this queue as existing
		$Redis->hset('C3|Rabbit|queue|'.$queue->{'name'},'time',time(),sub {});
		$Redis->expire('C3|Rabbit|queue|'.$queue->{'name'},60,sub {});
		
		main::_log("active queue '$queue->{'name'}' domain='$domain' jobs=".$queue->{'messages_ready'}." rate=".$queue->{'messages_ready_details'}->{'rate'}." consumers=".$queue->{'consumers'})
			if (
#				$queue->{'consumers'} ||
				$queue->{'messages_ready'} ||
				$queue->{'messages_ready_details'}->{'rate'}
			);
		
		if (!$domain_info{$domain} && ($domain ne "_global"))
		{
#			main::_log_stdout(" unknown domain '$domain' with jobs=".$queue->{'messages_ready'},1,"job.workerd");
			if (!$queue->{'messages_ready'})
			{
#				main::_log_stdout("queue '$queue->{'name'}' unknown, removing",1,"job.workerd");
#				async {
#					$service->_channel->delete_queue(
##						'exchange' => encode('UTF-8', 'cyclone3.job'),
#						'queue' => encode('UTF-8', 'cyclone3.job.'.$domain)
#					);
#				}
			}
			next;
		}
		
		last if $WORKERS >= $MAX_WORKERS;
		
		# check consumers
		if ($class && $domain && !$queue->{'consumers'} && $queue->{'messages_ready'})
		{
			my $t = new Proc::ProcessTable;
			my $workers_local=(scalar (grep {$_->{'cmndline'}=~/^c3\-job\.worker \[$domain\] :$class /;} @{$t->table}))-1;
			$queue->{'consumers'} = $workers_local
				if $workers_local > $queue->{'consumers'};
			main::_log("real local consumers=".$queue->{'consumers'}." in domain=$domain class=$class");
		}
		elsif ($class && $domain && $queue->{'messages_ready'})
		{
			main::_log("consumers=".$queue->{'consumers'}." in domain=$domain class=$class");
		}
		
		if ($class && exists $TOM::job_class_max_workers{$class})
		{
			next if $TOM::job_class_max_workers{$class} <= $queue->{'consumers'};
		}
		next if $TOM::job_domain_max_workers <= $queue->{'consumers'};
		next if ($domain_worker{$domain.$class_}{'request_time'} >= (time() - $TOM::job_domain_worker_start_delay));
		
		if ($queue->{'messages_ready'}) # !$queue->{'consumers'} && 
		{
			main::_log_stdout("starting new worker for '$domain$class_'",3,"job.workerd");
			
			$domain_worker{$domain.$class_}{'request_time'}=time();
#			$domain_worker{$domain.$class_}{'count'}++;
			
			$tom::P__=$domain_info{$domain}{'tom::P'} || $TOM::P.'/.core'; # new local.conf location
			chdir $tom::P__;
			my $cmd='/usr/bin/perl '.$TOM::P."/.core/job.worker $class > /dev/null";
#			main::_log_stdout("chdir '$tom::P__' exec '$cmd'",3,"job.workerd");
			`$cmd&`;
#			sleep 2;
			$WORKERS++;
			$started++;
#			main::_log_stdout("started new worker",3,"job.workerd");
			last if $started >= int($sysstat->{'tcpucount'}/2);
		}
	}
	
}) if $ENV{'WORKERS'};

my $w=AnyEvent->timer(after => 0, interval => 0.5, cb => \&monitor_master_db)
	if ($TOM::DB{'main:1'} && $main::arg{'mode'} eq "master");
sub monitor_master_db
{
#	main::_log("check db");
	use Time::HiRes qw( usleep ualarm gettimeofday tv_interval );
	my ($seconds, $microseconds) = gettimeofday;
	my $ttime=$seconds.'.'.$microseconds;
#	main::_log("insert master $ttime");
	$Redis->set('C3|db_main|modified',$ttime,sub{});
	$Redis->expire('C3|db_main|modified',86400,sub {});
	TOM::Database::SQL::execute(qq{REPLACE INTO TOM.a100_master (ID,datetime_create,timestamp) VALUES (1,FROM_UNIXTIME($ttime),$ttime)},'quiet'=>1);
}

my $w=AnyEvent->timer(after => 60, interval => 30, cb => \&check_domains);
my $w=AnyEvent->timer(after => 0, interval => 1, cb => \&check_scheduler)
	if $main::arg{'mode'} eq "master";
my $w=AnyEvent->timer(after => 600, interval => 600, cb => \&check_processes);

sub check_domains
{
	$main::request_code=Utils::vars::genhash(8);
	if ($ENV{'AUTORESTART'} && (time()-$main::time_current) >= (600))
	{ # restart every 6h
		main::_log("running too long, restarting");
		exit;
	}
	
	local $main::_canexit;
	
	my %domains=@{$Redis->hgetall('C3|domains')};
	
#	main::_log("check_domains");
#	main::_log("active ".scalar(keys %domains)." domains (".(join(",",sort keys %domains)).")",3,"job.workerd");
	
	foreach my $domain (sort {length($a) <=> length($b) || $a cmp $b} keys %domains)
	{
		my $dom_data=from_json $domains{$domain};
			$dom_data->{'tom::P'}=$TOM::P.'/'.$dom_data->{'tom::P_rel'}
				if $dom_data->{'tom::P_rel'};
			$dom_data->{'tom::P_rel'}=$dom_data->{'tom::P'};
				$dom_data->{'tom::P_rel'}=~s|^$TOM::P/||;
			$dom_data->{'domain'}=$domain;
		$domains{$domain}=to_json $dom_data;
		
#		main::_log(" domain='$domain' old=".(time()-$dom_data->{'updated'}));
#		print Dumper($dom_data);
#		exit if $domain eq "play.markiza.sk";
		
		if (!-d $dom_data->{'tom::P'} || ($dom_data->{'updated'} < (time() - (86400 * 2))))
		{
			# ignoring domain
			$Redis->hdel('C3|domains',$domain,sub{});
			main::_log_stdout("removing inactive domain '$domain' (".($dom_data->{'tom::P'}).") from register",1,"job.workerd");
			delete $domains{$domain};
			next;
		}
		
		$domain_info{$domain}=$dom_data;
		
#=head1
		if ((time()-$dom_data->{'updated'}) < 3600){async {
		
			# create queue
#			main::_log("re-create queue for $domain");
			# cyclone3.job.domain.tld: cyclone3.job -> cyclone3.job
			$service->_channel->declare_queue(
				'exchange' => encode('UTF-8', 'cyclone3.job'),
				'queue' => encode('UTF-8', 'cyclone3.job.'.$domain),
				'durable' => 1
			);
			$service->_channel->bind_queue(
				'exchange' => encode('UTF-8', 'cyclone3.job'),
				'routing_key' => encode('UTF-8', $domain),
				'queue' => encode('UTF-8', 'cyclone3.job.'.$domain)
			);
			
			$service->_channel->declare_queue(
				'exchange' => encode('UTF-8', 'cyclone3.job'),
				'queue' => encode('UTF-8', 'cyclone3.job.db:'.$domain_info{$domain}->{'db_name'}),
				'durable' => 1
			);
			$service->_channel->bind_queue(
				'exchange' => encode('UTF-8', 'cyclone3.job'),
				'routing_key' => encode('UTF-8', 'db:'.$domain_info{$domain}->{'db_name'}),
				'queue' => encode('UTF-8', 'cyclone3.job.db:'.$domain_info{$domain}->{'db_name'})
			);
#			$service->_channel->bind_queue(
#				'exchange' => encode('UTF-8', 'cyclone3.job'),
#				'routing_key' => encode('UTF-8', 'db:'.$dom_data->{'db_name'}),
#				'queue' => encode('UTF-8', 'cyclone3.job.'.$domain)
#			);
			
		};}
#=cut
		
	}
	
	# load or update job.conf files
	foreach my $domain ('_global',sort {length($a) <=> length($b) || $a cmp $b} keys %domains)
	{
#		main::_log("domain = $domain");
		my $dom_data={};
			if ($domain ne "_global")
			{
				$dom_data=from_json $domains{$domain};
				$dom_data->{'domain'}=$domain;
			}
			else
			{
				$dom_data->{'tom::P'}=$TOM::P.'/_config';
				$dom_data->{'domain'}='_global';
			}
		
		$domain_info{$domain}=$dom_data;
		
#		main::_log_stdout("domain '$domain' config dir ".$dom_data->{'tom::P'}." \"last_invocation\"=-".(time()-$dom_data->{'updated'})."s");
		
#		print Dumper($dom_data);
		
		# check if there are special triggers definition file (jobs.conf)
		my $filename=$dom_data->{'tom::P'}.'/job.conf';
		if (-e $filename && (stat($filename))[9] > $config_file{$filename}{'mtime'})
		{
			main::_log_stdout(" loading '".($dom_data->{'tom::P'}.'/job.conf')."' mtime=".(stat($filename))[9],3,"job.workerd");
			
			# start parsing file
			use XML::Simple;
			my $data = eval {XMLin($filename,
				'KeyAttr' => {'trigger'=>'id'},
				'ForceArray' => [ 'trigger','exec' ],
			)};
			
			if ($@)
			{
				main::_log_stdout(" can't parse '$filename' ($@)",1,"job.workerd");
				$config_file{$filename}{'mtime'}=(stat($filename))[9];
				next;
			}
			
#			print Dumper($data);
			
			$config_file{$filename}{'mtime'}=(stat($filename))[9];
			$config_file{$filename}{'domain'}=$dom_data;
			$config_file{$filename}{'trigger'}=$data->{'trigger'};
			$config_file{$filename}{'exec'}=$data->{'exec'};
			
			main::_log_stdout(" ".(keys %{$config_file{$filename}{'trigger'}})." trigger(s) found (".
				(join ",",keys %{$config_file{$filename}{'trigger'}})
			.")");
			
			# write cron definitions
			# but only if i'm master
			next unless $main::arg{'mode'} eq "master";
			foreach my $id(grep {$config_file{$filename}{'trigger'}{$_}{'type'} eq "cron"} keys %{$config_file{$filename}{'trigger'}})
			{
				my $cron=$config_file{$filename}{'trigger'}{$id};
				if (!$cron->{'cron-schedule'} && !$cron->{'cron-run-every'})
				{
					main::_log_stdout(" job '$id' missing \@cron-schedule||\@cron-run-every definition",1,"job.workerd");
					next;
				}
				
				if ($cron->{'cron-run-every'})
				{
					my %sth0=TOM::Database::SQL::execute(qq{
						SELECT
							*,
							UNIX_TIMESTAMP(datetime_next) AS unixtime_next,
							IF(datetime_next < NOW(),'before','future') AS status_now
						FROM
							`TOM`.`a100_job_cron_schedule`
						WHERE
							`filename`=? AND
							`id`=? AND
							`status`='Y'
						LIMIT 1
					},'db_h'=>'sys','bind'=>[
						$filename,
						$id
					],'quiet'=>1);
					my %db0_line=$sth0{'sth'}->fetchhash();
					
					my $datetime_next=time();
					if ($cron->{'cron-run-every'}=~/^(\d+)S$/i)
					{
						$datetime_next+=$1;
					}
					elsif ($cron->{'cron-run-every'}=~/^(\d+)M$/i)
					{
						$datetime_next+=(60 * $1);
					}
					elsif ($cron->{'cron-run-every'}=~/^(\d+)H$/i)
					{
						$datetime_next+=(3600 * $1);
					}
					elsif ($cron->{'cron-run-every'}=~/^(\d+)D$/i)
					{
						$datetime_next+=(86400 * $1);
					}
					
					if (!$db0_line{'status_now'})
					{
						main::_log_stdout(" [$domain] set cron '".$id."' to execute every '".($cron->{'cron-run-every'})."', after ".($datetime_next-time())."S from now",3,"job.workerd");
						TOM::Database::SQL::execute(qq{
							REPLACE INTO
								`TOM`.`a100_job_cron_schedule`
							SET
								`filename`=?,
								`id`=?,
								`cron-schedule`=NULL,
								`cron-run-every`=?,
								`datetime_create`=NOW(),
								`datetime_next`=FROM_UNIXTIME(?),
								`status`='Y'
						},'db_h'=>'sys','bind'=>[
							$filename,
							$id,
							$cron->{'cron-run-every'},
							$datetime_next
						],'quiet'=>1);
						next;
					}
					
#					exit;
					
					if ($db0_line{'status_now'} eq "before")
					{
#						main::_log("running is in plan");
					}
					else
					{
#						main::_log("next is ".($db0_line{'unixtime_next'})." calculated $datetime_next");
						if ($datetime_next < $db0_line{'unixtime_next'})
						{
							main::_log_stdout(" [$domain] set cron '".$id."' to execute every '".($cron->{'cron-run-every'})."', after ".($datetime_next-time())."S from now",3,"job.workerd");
							
							TOM::Database::SQL::execute(qq{
								REPLACE INTO
									`TOM`.`a100_job_cron_schedule`
								SET
									`filename`=?,
									`id`=?,
									`cron-schedule`=NULL,
									`cron-run-every`=?,
									`datetime_create`=NOW(),
									`datetime_next`=FROM_UNIXTIME(?),
									`status`='Y'
							},'db_h'=>'sys','bind'=>[
								$filename,
								$id,
								$cron->{'cron-run-every'},
								$datetime_next
							],'quiet'=>1);
							next;
						}
					}
					
					my %sth0=TOM::Database::SQL::execute(qq{
						UPDATE
							`TOM`.`a100_job_cron_schedule`
						SET
							`datetime_create`=NOW(),
							`cron-run-every`=?,
							`cron-schedule`=NULL
						WHERE
							`filename`=? AND
							`id`=?
						LIMIT 1
					},'db_h'=>'sys','bind'=>[
						$cron->{'cron-run-every'},
						$filename,
						$id
					],'quiet'=>1);
					
					main::_log_stdout(" [$domain] set cron '".$id."' to execute every '".($cron->{'cron-run-every'})."', planned ".($db0_line{'unixtime_next'}-time())."S before now",3,"job.workerd");
					
					next;
				}
				
				my $datetime_next=TOM::Engine::job::cron::get_next_execution_time($cron->{'cron-schedule'},time());
				
				my %sth0=TOM::Database::SQL::execute(qq{
					SELECT
						*,
						IF(datetime_next < NOW(),'before','future') AS status_now
					FROM
						`TOM`.`a100_job_cron_schedule`
					WHERE
						`filename`=? AND
						`id`=? AND
						`status`='Y'
					LIMIT 1
				},'db_h'=>'sys','bind'=>[
					$filename,
					$id
				],'quiet'=>1);
				my %db0_line=$sth0{'sth'}->fetchhash();
				
				if ($db0_line{'status_now'} eq "before")
				{
#					main::_log_stdout(" [$domain] set cron '".$id."' first execute after ".($datetime_next-time())."S",3,"job.workerd");
					
					my %sth0=TOM::Database::SQL::execute(qq{
						UPDATE
							`TOM`.`a100_job_cron_schedule`
						SET
							`datetime_create`=NOW(),
							`cron-run-every`=NULL,
							`cron-schedule`=?
						WHERE
							`filename`=? AND
							`id`=?
						LIMIT 1
					},'db_h'=>'sys','bind'=>[
						$cron->{'cron-schedule'},
						$filename,
						$id
					],'quiet'=>1);
				}
				else
				{
					main::_log_stdout(" [$domain] set cron '".$id."' to execute after ".($datetime_next-time())."S from now",3,"job.workerd");
					TOM::Database::SQL::execute(qq{
						REPLACE INTO
							`TOM`.`a100_job_cron_schedule`
						SET
							`filename`=?,
							`id`=?,
							`cron-schedule`=?,
							`cron-run-every`=NULL,
							`datetime_create`=NOW(),
							`datetime_next`=FROM_UNIXTIME(?),
							`status`='Y'
					},'db_h'=>'sys','bind'=>[
						$filename,
						$id,
						$cron->{'cron-schedule'},
						$datetime_next
					],'quiet'=>1);
				}
				
			}
			
			# disable others
			my $crons=join "','",
				grep {$config_file{$filename}{'trigger'}{$_}{'type'} eq "cron"}
				keys %{$config_file{$filename}{'trigger'}};
			
			TOM::Database::SQL::execute(qq{
				UPDATE
					`TOM`.`a100_job_cron_schedule`
				SET
					`status`='N'
				WHERE
					filename=? AND
					status='Y' AND
					id NOT IN ('$crons')
			},'db_h'=>'sys','bind'=>[
				$filename
			],'quiet'=>1);
		}
		elsif (!-e $filename)
		{
			delete $config_file{$filename};
			next;
		}
		
	}
	
	# remove not existing definitions
	foreach (keys %config_file)
	{
		delete $config_file{$_}
			unless -e $_;
	}
	
}


sub check_scheduler
{
	$main::request_code=Utils::vars::genhash(8);
	local $main::_canexit;
	my %sth0=TOM::Database::SQL::execute(qq{
		SELECT
			*
		FROM
			`TOM`.`a100_job_cron_schedule`
		WHERE
			datetime_next < NOW()
			AND status = 'Y'
		ORDER BY
			datetime_next
	},'db_h'=>'sys','quiet'=>1);
	while (my %db0_line=$sth0{'sth'}->fetchhash())
	{
		my $filename=$db0_line{'filename'};
		my $config=$config_file{$filename};
		if (!$config)
		{
			main::_log_stdout("missing config '$filename'",1,"job.workerd");
			
			TOM::Database::SQL::execute(qq{
				UPDATE
					`TOM`.`a100_job_cron_schedule`
				SET
					`status`='E'
				WHERE
					filename=? AND
					id = ?
			},'db_h'=>'sys','bind'=>[
				$filename,
				$db0_line{'id'}
			],'quiet'=>1);
			
			next;
		}
		
		my $domain=$config->{'domain'}->{'domain'};
		
		my @domains=($domain);
		
#		print Dumper($domain);
		next unless $domain;
#		print Dumper($config->{'domain'}->{'domain'});
		
		# jobify
		my $cron=$config->{'trigger'}{$db0_line{'id'}};
		
		my $class;
			$class.="::".$cron->{'job-class'}
				if $cron->{'job-class'};
		
#		print Dumper($cron);
		
		
		if ($cron->{'run-on-each'} eq "domain")
		{
			@domains=();
			foreach my $domain_ (sort {length($a) <=> length($b) || $a cmp $b} keys %domain_info)
			{
				next unless $domain_info{$domain_}{'db_name'};
#				print Dumper()
#				main::_log_stdout("test domain '$domain_'",3,"job.workerd");
				push @domains, $domain_;
			}
		}
		elsif ($cron->{'run-on-each'} eq "database")
		{
			my %database_;
			@domains=();
			foreach my $domain_ (sort {length($a) <=> length($b) || $a cmp $b} keys %domain_info)
			{
				next unless $domain_info{$domain_}{'db_name'};
				
				if ($cron->{'run-if-addon'})
				{
					next unless $domain_info{$domain_}{'addons'}{$cron->{'run-if-addon'}};
					next if $database_{$domain_info{$domain_}{'addons'}{$cron->{'run-if-addon'}}};
					$database_{$domain_info{$domain_}{'addons'}{$cron->{'run-if-addon'}}}++;
					
					main::_log_stdout("test domain '$domain_' db_name='$domain_info{$domain_}{'db_name'}'",3,"job.workerd");
					
					push @domains, $domain_;
				}
				else
				{
					next if $database_{$domain_info{$domain_}{'db_name'}};
					$database_{$domain_info{$domain_}{'db_name'}}++;
					
#					main::_log_stdout("test domain '$domain_' db_name='$domain_info{$domain_}{'db_name'}'",3,"job.workerd");
					
					push @domains, $domain_;
				}
			}
		}
		
		foreach $domain (@domains)
		{
			main::_log_stdout("[$domain] jobify cron '$db0_line{'id'}' scheduled to '".$db0_line{'datetime_next'}."'",3,"job.workerd");
			
#			next;
			
			my $routing_key=$domain;
				$routing_key="job" if $routing_key eq "_global";
				$routing_key.=$class if $class;
			
			my $queue=$domain;
				$queue.=$class if $class;
			
			if ($cron->{'job-name'})
			{
				
				my $queue_found;
				if ($Redis)
				{
					$queue_found=$Redis->hget('C3|Rabbit|queue|'.'cyclone3.job.'.$queue,'time');
					$Redis->hset('C3|Rabbit|queue|'.'cyclone3.job.'.$queue,'time',time(),sub {});
					$Redis->expire('C3|Rabbit|queue|'.'cyclone3.job.'.$queue,60,sub {});
				}
				if (!$queue_found)
				{
					async {
						main::_log("declare_queue ".'cyclone3.job.'.$queue);
						$service->_channel->declare_queue(
							'exchange' => encode('UTF-8', 'cyclone3.job'),
							'queue' => encode('UTF-8', 'cyclone3.job.'.$queue),
							'durable' => 1
						);
						$service->_channel->bind_queue(
							'exchange' => encode('UTF-8', 'cyclone3.job'),
							'routing_key' => encode('UTF-8', $routing_key),
							'queue' => encode('UTF-8', 'cyclone3.job.'.$queue)
						);
					};
				}
				
				main::_log_stdout(" job-name '".$cron->{'job-name'}.$class."'",3,"job.workerd");
				$do->job({'deduplication'=>'true','routing_key' => $routing_key},{
					'name' => $cron->{'job-name'},
					'schedule-entry' => {
						'filename' => $db0_line{'filename'},
						'id' => $db0_line{'id'}
					}
				});
				
			}
			elsif ($cron->{'content'})
			{
				
				eval $cron->{'content'};
				if ($@)
				{
					main::_log("$@",1);
				}
				
			}
			
		}
		
#		next;
		
		if ($db0_line{'cron-run-every'})
		{
#			main::_log(" cron-run-every='$db0_line{'cron-run-every'}'");
			my $datetime_next=time();
			if ($db0_line{'cron-run-every'}=~/^(\d+)S$/i)
			{
				$datetime_next+=$1;
#				main::_log(" +$1S");
			}
			elsif ($db0_line{'cron-run-every'}=~/^(\d+)M$/i)
			{
				$datetime_next+=(60 * $1);
#				main::_log(" +$1M");
			}
			elsif ($db0_line{'cron-run-every'}=~/^(\d+)H$/i)
			{
				$datetime_next+=(3600 * $1);
#				main::_log(" +$1H");
			}
			elsif ($db0_line{'cron-run-every'}=~/^(\d+)D$/i)
			{
				$datetime_next+=(86400 * $1);
#				main::_log(" +$1D");
			}
#			main::_log(" cron-run-every='$db0_line{'cron-run-every'}'");
			
			my %sth0=TOM::Database::SQL::execute(qq{
				UPDATE
					`TOM`.`a100_job_cron_schedule`
				SET
					`datetime_past_jobify`=NOW(),
					`datetime_next`=FROM_UNIXTIME(?)
				WHERE
					`filename`=? AND
					`id`=?
				LIMIT 1
			},'db_h'=>'sys','bind'=>[
				$datetime_next,
				$filename,
				$db0_line{'id'}
			],'quiet'=>1);
			
			main::_log_stdout(" next exec after ".($datetime_next-time())."S",3,"job.workerd");
			next;
		}
		
		my $datetime_next=TOM::Engine::job::cron::get_next_execution_time($db0_line{'cron-schedule'},time());
		
		my %sth0=TOM::Database::SQL::execute(qq{
			UPDATE
				`TOM`.`a100_job_cron_schedule`
			SET
				`datetime_past_jobify`=NOW(),
				`datetime_next`=FROM_UNIXTIME(?)
			WHERE
				`filename`=? AND
				`id`=?
			LIMIT 1
		},'db_h'=>'sys','bind'=>[
			$datetime_next,
			$filename,
			$db0_line{'id'}
		],'quiet'=>1);
		
		main::_log_stdout(" next exec after ".($datetime_next-time())."S",3,"job.workerd");
	}
#	exit;
}



sub check_processes
{
	$main::request_code=Utils::vars::genhash(8);
	local $main::_canexit;
	
	my $t = new Proc::ProcessTable;
	
	foreach my $proc (grep {$_->{'cmndline'}=~/^c3\-job\.worker[^d]/;} @{$t->table})
	{
		my $durr=time() - $proc->{'start'};
		next unless $durr >= 3600;
		
		main::_log("long running process $proc->{'pid'} '".$proc->{'cmndline'}."' cpu=".($proc->{'pctcpu'}+0)."% running=".int($durr/60)."m",3,"job.workerd");
		my $vals={@{$Redis->hgetall('c3process|'.$TOM::hostname.':'.$proc->{'pid'})}};
		
		if ($proc->{'cmndline'}=~/\{\}/ && !$vals->{'time'})
		{
			main::_log("long running process $proc->{'pid'} '".$proc->{'cmndline'}."' cpu=".($proc->{'pctcpu'}+0)."% running=".int($durr/60)."m to kill",4,"job.workerd");
			kill 15, $proc->{'pid'};
		}
		
	}
}



# read notify messages
sub callback
{
	local $main::_canexit;
	my $var = shift;
	my $body = from_json($var->{'body'}->{'payload'});
	
	my $timestamp=$var->{'header'}->{'timestamp'};
	my $user_id=$var->{'header'}->{'user_id'};
	my $delivery_tag=$var->{'deliver'}->{'method_frame'}->{'delivery_tag'};
	my $routing_key=$var->{'deliver'}->{'method_frame'}->{'routing_key'};
	
#	print Dumper($body);
	
	if (!$body->{'event'})
	{
		#main::_log_stdout("",3,"job");
		main::_log("not defined any type of event",1);
		return $notify_channel->ack();
	}
	
	main::_log("event='$body->{'event'}' '$body->{'key'}'")
		unless $body->{'key'}=~/^main::TOM::a010_test::\d+$/; # this is only for testing purposes
	
	if ($body->{'event'} eq "db_changed" && $Redis)
	{
		# invalidate all caches depending on this key
		my $key_entity="C3|invalidate|db_entity|".$body->{'key'};
#		main::_log("check to invalidate '$key_entity'");
		foreach (@{$Redis->smembers($key_entity)})
		{
			
			if (my $warmup=$Redis->hget($_,'warmup'))
			{
				$warmup=from_json(Ext::Redis::_uncompress(\$warmup));
				
				my $key=$_;
				main::_log("warmup cache key '$key'");
				
				use TOM::Utils::vars;
				use Utils::datetime;
				my $id=TOM::Utils::vars::genhash(8);
				my $warmup_time=int( time()/$TOM::CACHE_warmup_granularity ) * $TOM::CACHE_warmup_granularity;
				my %date=Utils::datetime::ctodatetime($warmup_time,format=>1);
				my $datetime_string=$date{'year'}."-".$date{'mon'}."-".$date{'mday'}." ".$date{'hour'}.":".$date{'min'}.":".$date{'sec'};
				
				my $mdl_cache_type='C3|'.$TOM::CACHE_warmup_cache_name.'|'.$warmup_time;
					$Redis->sadd($mdl_cache_type, $key);
					$Redis->expire($mdl_cache_type,(86400 * 30 * 2));
				
				main::_log("entity '".($body->{'key'})."' changed, create immediately warmup request '$key' '$id'",{
					'severity' => 3,
					'facility' => 'warmup',
					'data' => {
						'id_s' => $key,
						'mdl_s' => $warmup->{'body'}->{'pub-mdl'},
						'engine_s' => $TOM::engine,
						'requested_routing_key_s' => $warmup->{'routing_key'},
						'requested_id_s' => $id,
						'requested_datetime_s' => $datetime_string
					}
				});
				
			}
			else
			{
				main::_log("remove cache key '$_'");
				$Redis->del($_,sub{});
			}
		}
		$Redis->del($key_entity,sub{});
	}
	
	foreach my $filename (keys %config_file)
	{
#		my $content;
#		print "file=$file\n";
		
#		print "".$config_file{$file}->{'domain'}->{'domain'}."\n";
		
		if (
			$config_file{$filename}->{'domain'}->{'domain'} eq $body->{'domain'}
			|| $config_file{$filename}->{'domain'}->{'domain'} eq "_global"
		)
		{
#			print "file=$filename\n";
			
			foreach my $id(
				grep {$config_file{$filename}{'trigger'}{$_}{'notify-event'} eq $body->{'event'}}
				grep {$config_file{$filename}{'trigger'}{$_}{'type'} eq "notify"}
				keys %{$config_file{$filename}{'trigger'}})
			{
				
				my $trigger=$config_file{$filename}{'trigger'}{$id};
				
				if (
					$body->{'event'} eq "db_changed" &&
					$trigger->{'notify-event-tb_name'} eq $body->{'tb_name'})
				{
#					print Dumper($trigger);
					main::_log(" eval trigger '$id'");
					eval $trigger->{'content'};
					if ($@)
					{
						main::_log("$@",1);
					}
				}
				
#				if (!$cron->{'cron-schedule'})
#				{
#					main::_log_stdout(" job '$id' missing \@cron-schedule definition",1,"job.workerd");
#				}
			}
			
		}
	}
	
	return $notify_channel->ack();
}

$notify_channel->qos(
	prefetch_count => 10,
	prefetch_size => 10
);
$notify_channel->consume(
	on_consume => \&callback,
	no_ack => 0,
);

$main_loop->recv;

package class_do;
use open ':utf8', ':std';
use if $] < 5.018, 'encoding','utf8';
use utf8; # encode = fromutf8, decode=toutf8
use strict; # scrict code
use Ext::RabbitMQ::_init;
use JSON;
use Data::Dumper;

sub new
{
	my $class=shift;
	my $obj=bless {}, $class;
	
	
	
	return $obj;
}

sub job
{
	my $self=shift;
	my $header=shift;
	my $job=shift;
	my $args=shift;
	
#	print Dumper($header,$job,$args);
	my $id=TOM::Utils::vars::genhash(8);
	
	main::_log("{jobify} job '".($job->{'file'} || $job->{'name'})."' routing_key='".($header->{'routing_key'} || 'job')."' id='$id' deduplication=".$header->{'deduplication'},{
		'data' => {
			'payload_s' => to_json({
				'job' => $job,
				'args' => $args
			})
		}
	});
	
	my %headers;
		$headers{'deduplication'} = 'true'
			if $header->{'deduplication'};
			
	$main::service->publish(
		'exchange' => 'cyclone3.job',
		'routing_key' => ($header->{'routing_key'} || 'job'),
		'body' => to_json({
			'job' => $job,
			'args' => $args
		}),
		'header' => {
			'headers' => {
				'message_id' => $id,
				%headers
			}
		}
	) || do {
		main::_log("oh, shit, workerd not working",1);
		exit;
	};
	
#	print Dumper($main::service);
}

1;
